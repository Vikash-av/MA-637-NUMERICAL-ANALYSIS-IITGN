{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlPzX5INjSFSP58k0HUK4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vikash-av/MA-637-NUMERICAL-ANALYSIS-IITGN-/blob/main/Assignment_6(qno4).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BwwVFXv8lhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d03757-eb39-49f6-fe32-02d63d5152e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Choosen Method  : SOR\n",
            "Maximum Iteration : 100\n",
            "Tolerance : 1e-10\n",
            "Omega for SOR : 1.0\n",
            "Method Unknown : SOR\n",
            "Method Unknown : SOR\n",
            "Method Unknown : SOR\n",
            "Solution :[0. 0. 0.]\n",
            "Convergence reached with 1 number of iterations \n",
            "Choosen Method  : jacobi\n",
            "Maximum Iteration : 100\n",
            "Tolerance : 1e-10\n",
            "Solution :[0. 0. 0.]\n",
            "Convergence reached with 1 number of iterations \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "#we will first compute the omega used in the sor iterative method\n",
        "\n",
        "def optimal_omega(A):\n",
        "  omega = 0.0\n",
        "  n = np.shape(A)[0]\n",
        "  L = np.zeros((n,n))\n",
        "  D = np.zeros((n,n))\n",
        "  U = np.zeros((n,n))\n",
        "\n",
        "  #Now, Computing matrix L, D, and U\n",
        "\n",
        "  for i in range(n):\n",
        "    for j in range(n):\n",
        "      if ( i < j):\n",
        "        U[i][j] = -A[i][j]\n",
        "      elif i > j:\n",
        "        L[i][j] == -A[i][j]\n",
        "      else:\n",
        "        D[i][j] = A[i][j]\n",
        "\n",
        "  T = np.zeros ((n,n))\n",
        "\n",
        "  #iteration matrix for jacobi method\n",
        "\n",
        "  T = np.dot(np.linalg.inv(D), (L+U))   #(have some doubts)\n",
        "\n",
        "  #now, computing all eigenvalues\n",
        "\n",
        "  eigenvalue = np.linalg.eigvalsh(T)\n",
        "\n",
        "  #abs_eigenvalue = np.abs(eigenvalue)\n",
        "\n",
        "  #spectral_radius = max(abs_eigenvalue)\n",
        "  spectral_radius = np.abs(eigenvalue[np.size(eigenvalue)-1])\n",
        "\n",
        "  omega = 2 / (1 + np.sqrt(1 - spectral_radius**2))\n",
        "\n",
        "  return omega\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "  #creating matrix A\n",
        "\n",
        "  #A = np.array([[10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8]])\n",
        "  A = np.array([[4,3,0], [3,4,-1], [0,-1,4]])\n",
        "  #b = np.array([6, 25, -11, 15])\n",
        "  b = np.array([1, 2, 0])\n",
        "\n",
        "  #choose, Jacobi, SOR, GS\n",
        "  method = \"SOR\"\n",
        "\n",
        "  maximum_iteration = 100\n",
        "  tolerance = 1e-10\n",
        "  omega = optimal_omega(A)                       # changing omega\n",
        "  print(f\"Choosen Method  : {method}\")\n",
        "  print(f\"Maximum Iteration : {maximum_iteration}\")\n",
        "  print(f\"Tolerance : {tolerance}\")\n",
        "\n",
        "  if (method == \"SOR\"):\n",
        "    print(f\"Omega for SOR : {omega}\")\n",
        "\n",
        "  if (method == \"GS\"):\n",
        "    omega = 1\n",
        "\n",
        "  #Dimension\n",
        "  n = np.shape(A)[0]\n",
        "  x = np.zeros(n)\n",
        "\n",
        "  # Initial iterate is set to zero. We call it old_iterate as we copy these values\n",
        "  # for the next iterative process.\n",
        "  old_iterate = np.zeros(n)\n",
        "\n",
        "  # Loop over the maximum number of iteration\n",
        "\n",
        "  for iterate in range(maximum_iteration):\n",
        "    # SOR iteration\n",
        "\n",
        "    for i in range(n):\n",
        "      sum = b[i]\n",
        "      for j in range(n):\n",
        "        if method == \"jacobi\":\n",
        "          if i != j:\n",
        "            sum -= A[i][j] * old_iterate[j]\n",
        "        elif method == \"SOR\" or method == \"GS\":\n",
        "          if j < i :\n",
        "            sum -= A[i][j] * x[j]\n",
        "          elif i < j :\n",
        "            sum -= A[i][j] * old_iterate[j]\n",
        "\n",
        "          else:\n",
        "            print(f\"Method Unknown : {method}\")\n",
        "            exit()\n",
        "\n",
        "    # Update the value of xi\n",
        "    x[i] = (1 - omega) * old_iterate[i] + omega * (sum/ A[i][i])\n",
        "    # Compute the error between the successive iteration steps. We are using the\n",
        "    # l_inf norm.\n",
        "\n",
        "    error = np.linalg.norm(x - old_iterate, ord=np.inf)\n",
        "    if error < tolerance:\n",
        "      print(f\"Solution :{x}\")\n",
        "      print(f\"Convergence reached with {iterate+1} number of iterations \")\n",
        "      break\n",
        "\n",
        "    # Copy the old solution vector\n",
        "    # NOTE: If we use old_iterate = x, then it is incorrect as it's not copying but a new\n",
        "    #       reference to the old variable.\n",
        "\n",
        "    old_iterate = np.copy(x)\n",
        "    # In Python you can use a else with a for loop, in the case maximum number of iteration\n",
        "    # is reached, i.e., the code doesn't break, then we execute the else part\n",
        "  else:\n",
        "        print(f\"Maximum iterations reached without Convergence\")\n",
        "\n",
        "\n",
        "##################################################################\n",
        "  #choose, Jacobi, SOR, GS\n",
        "  method = \"jacobi\"\n",
        "\n",
        "  maximum_iteration = 100\n",
        "  tolerance = 1e-10\n",
        "  omega = optimal_omega(A)                       # changing omega\n",
        "  print(f\"Choosen Method  : {method}\")\n",
        "  print(f\"Maximum Iteration : {maximum_iteration}\")\n",
        "  print(f\"Tolerance : {tolerance}\")\n",
        "\n",
        "  if (method == \"SOR\"):\n",
        "    print(f\"Omega for SOR : {omega}\")\n",
        "\n",
        "  if (method == \"GS\"):\n",
        "    omega = 1\n",
        "\n",
        "  #Dimension\n",
        "  n = np.shape(A)[0]\n",
        "  x = np.zeros(n)\n",
        "\n",
        "  # Initial iterate is set to zero. We call it old_iterate as we copy these values\n",
        "  # for the next iterative process.\n",
        "  old_iterate = np.zeros(n)\n",
        "\n",
        "  # Loop over the maximum number of iteration\n",
        "\n",
        "  for iterate in range(maximum_iteration):\n",
        "    # SOR iteration\n",
        "\n",
        "    for i in range(n):\n",
        "      sum = b[i]\n",
        "      for j in range(n):\n",
        "        if method == \"jacobi\":\n",
        "          if i != j:\n",
        "            sum -= A[i][j] * old_iterate[j]\n",
        "        elif method == \"SOR\" or method == \"GS\":\n",
        "          if j < i :\n",
        "            sum -= A[i][j] * x[j]\n",
        "          elif i < j :\n",
        "            sum -= A[i][j] * old_iterate[j]\n",
        "\n",
        "          else:\n",
        "            print(f\"Method Unknown : {method}\")\n",
        "            exit()\n",
        "\n",
        "    # Update the value of xi\n",
        "    x[i] = (1 - omega) * old_iterate[i] + omega * (sum/ A[i][i])\n",
        "    # Compute the error between the successive iteration steps. We are using the\n",
        "    # l_inf norm.\n",
        "\n",
        "    error = np.linalg.norm(x - old_iterate, ord=np.inf)\n",
        "    if error < tolerance:\n",
        "      print(f\"Solution :{x}\")\n",
        "      print(f\"Convergence reached with {iterate+1} number of iterations \")\n",
        "      break\n",
        "\n",
        "    # Copy the old solution vector\n",
        "    # NOTE: If we use old_iterate = x, then it is incorrect as it's not copying but a new\n",
        "    #       reference to the old variable.\n",
        "\n",
        "    old_iterate = np.copy(x)\n",
        "    # In Python you can use a else with a for loop, in the case maximum number of iteration\n",
        "    # is reached, i.e., the code doesn't break, then we execute the else part\n",
        "  else:\n",
        "        print(f\"Maximum iterations reached without Convergence\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "n=5\n",
        "b=np.zeros(n)\n",
        "c=np.zeros((n,n))\n",
        "print(b)\n",
        "print(c)\n",
        "e=[[-8,0],\n",
        "   [0,-4]]\n",
        "f = [[5,6],\n",
        "     [8,9]]\n",
        "print(np.add(e,f))\n",
        "print(np.linalg.inv(e))\n",
        "print(np.linalg.eigvalsh(e))\n",
        "eigen=(np.linalg.eigvalsh(e))\n",
        "sr = max(np.abs(eigen))\n",
        "print(sr)\n",
        "print(1e-10 - 1e-10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_lTtj-QAAtD",
        "outputId": "7d8cfedc-cc4b-4207-a121-7ded91b03dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0.]\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "[[-3  6]\n",
            " [ 8  5]]\n",
            "[[-0.125 -0.   ]\n",
            " [-0.    -0.25 ]]\n",
            "[-8. -4.]\n",
            "8.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Compute the Optimal Omega used in SOR iteration\n",
        "def optimal_omega(A):\n",
        "    omega = 0.0\n",
        "    n = np.shape(A)[0]\n",
        "    # The matrices L, D, and U\n",
        "    # FITB\n",
        "    L = np.zeros((n,n))\n",
        "    D = np.zeros((n,n))\n",
        "    U = np.zeros((n,n))\n",
        "    # Computation of the matrices L, D, and U\n",
        "    # FITB\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if i<j:\n",
        "                U[i][j] = -A[i][j]\n",
        "            elif i>j:\n",
        "                L[i][j] = -A[i][j]\n",
        "            else:\n",
        "                D[i][j] = A[i][j]\n",
        "    T = np.zeros((n,n))\n",
        "    # Iteration matrix for Jacobi method\n",
        "    # FITB\n",
        "    T = np.dot(np.linalg.inv(D), (L+U))\n",
        "    # Compute all the eigenvalues\n",
        "    eigenvalue = np.linalg.eigvals(T)\n",
        "    # Maximum eigenvalue\n",
        "    # FITB\n",
        "    spectral_radius = np.abs(eigenvalue[np.size(eigenvalue)-1])\n",
        "\n",
        "    # Optimal omega for SOR\n",
        "    # FITB\n",
        "    omega = 2/(1+np.sqrt(1-spectral_radius**2))\n",
        "\n",
        "    return omega\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create matrix A\n",
        "    #A = np.array([[10, -1, 2, 0], [-1, 11, -1, 3], [2, -1, 10, -1], [0, 3, -1, 8]])\n",
        "    A = np.array([[4,3,0], [3,4,-1], [0,-1,4]])\n",
        "    #b = np.array([6, 25, -11, 15])\n",
        "    b = np.array([1, 2, 0])\n",
        "\n",
        "    # Choose Jacobi, SOR, GS (Gauss Seidel)\n",
        "    method = \"SOR\"\n",
        "    # Maximum number of iteration and tolerance\n",
        "    max_iteration = 100\n",
        "    tolerance = 1e-10\n",
        "    omega = optimal_omega(A)\n",
        "    print(f\"Chosen Method     : {method}\")\n",
        "    print(f\"Maximum Iteration : {max_iteration}\")\n",
        "    print(f\"Tolerance         : {tolerance}\")\n",
        "    if method == \"SOR\":\n",
        "        print(f\"Omega for SOR     : {omega}\")\n",
        "\n",
        "    if method == \"GS\":  ## or method == Jacobi\n",
        "        # Set omega = ? for Gauss Seidel\n",
        "        # FITB\n",
        "        omega = 1\n",
        "\n",
        "    # Dimension\n",
        "    n = np.shape(A)[0]\n",
        "    x = np.zeros(n)\n",
        "\n",
        "    # Initial iterate is set to zero. We call it old_iterate as we copy these values\n",
        "    # for the next iterative process.\n",
        "    old_iterate = np.zeros(n)\n",
        "\n",
        "    # Loop over the maximum number of iteration\n",
        "    for iterate in range(max_iteration):\n",
        "        # SOR iteration\n",
        "        for i in range(n):\n",
        "            # FITB\n",
        "            sum = b[i]\n",
        "            for j in range(n):\n",
        "                if method == \"Jacobi\":\n",
        "                    if i!=j:\n",
        "                        sum -= A[i][j]*old_iterate[j]  # FITB\n",
        "                elif method == \"SOR\" or method == \"GS\":\n",
        "                    if j<i:\n",
        "                        sum -= A[i][j]*x[j]   # FITB\n",
        "                    elif i<j:\n",
        "                        sum -= A[i][j]*old_iterate[j]   # FITB\n",
        "                else:\n",
        "                    print(f\"Method Unknown : {method}\")\n",
        "                    exit()\n",
        "\n",
        "            # Update the values of x_i\n",
        "            # FITB\n",
        "            x[i] = (1-omega)*old_iterate[i] + omega*(sum/A[i][i])\n",
        "\n",
        "        # Compute the error between the successive iteration steps. We are using the\n",
        "        # l_inf norm.\n",
        "        # FITB\n",
        "        error = np.linalg.norm(x-old_iterate)\n",
        "        if error < tolerance:\n",
        "            print(f\"Solution          : {x}\")\n",
        "            print(f\"Convergence reached with {iterate+1} number of iterations\")\n",
        "            break\n",
        "\n",
        "        # Copy the old solution vector\n",
        "        # NOTE: If we use old_iterate = x, then it is incorrect as it's not copying but a new\n",
        "        #       reference to the old variable.\n",
        "        old_iterate = np.copy(x)\n",
        "    # In Python you can use a else with a for loop, in the case maximum number of iteration\n",
        "    # is reached, i.e., the code doesn't break, then we execute the else part\n",
        "    else:\n",
        "        print(f\"Maimum iterations reached without Convergence\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JDtC3tNVWUB",
        "outputId": "e1112798-f896-4825-f920-dfbd4caa430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen Method     : SOR\n",
            "Maximum Iteration : 100\n",
            "Tolerance         : 1e-10\n",
            "Omega for SOR     : 1.0\n",
            "Solution          : [-0.375       0.83333333  0.20833333]\n",
            "Convergence reached with 49 number of iterations\n"
          ]
        }
      ]
    }
  ]
}